class Tokeniser:
    def tokenise(self, text: str):
        """
        Splits the input text into a list of word tokens separated by whitespace.
        """
        return text.split()